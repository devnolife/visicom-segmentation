"""
Streamlit App untuk Flood Segmentation - All in One
"""
import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import io
import os
from streamlit_drawable_canvas import st_canvas
from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation

from models.unet import get_model
from utils.data_loader import get_inference_transform
from utils.visualization import overlay_mask
from utils.water_detection import detect_water_hsv, combine_detection_methods


# Konfigurasi halaman
st.set_page_config(
    page_title="Flood Segmentation System",
    page_icon="ðŸŒŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)


@st.cache_resource
def load_model(model_path, device='cpu'):
    """Load model dengan caching"""
    try:
        model = get_model('unet', n_channels=3, n_classes=2)
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        model.eval()
        return model, checkpoint.get('val_iou', 'N/A')
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None, None


def predict_flood(image, model, device, image_size=512):
    """Prediksi segmentasi banjir"""
    # Preprocess
    transform = get_inference_transform(image_size)
    image_rgb = np.array(image)
    original_size = image_rgb.shape[:2]
    
    transformed = transform(image=image_rgb)
    input_tensor = transformed['image'].unsqueeze(0).to(device)
    
    # Inference
    with torch.no_grad():
        output = model(input_tensor)
        probs = torch.softmax(output, dim=1)
        pred_mask = probs[:, 1, :, :].cpu().numpy()[0]
    
    # Resize to original
    pred_mask_resized = cv2.resize(pred_mask, (original_size[1], original_size[0]))
    
    return pred_mask_resized


def annotation_tool_page():
    """Halaman Annotation Tool dengan HSV Auto-detection"""
    st.title("âœï¸ Flood Mask Annotation Tool")
    st.markdown("**Tool untuk membuat anotasi mask area banjir dengan deteksi HSV otomatis**")
    
    # Settings
    col_settings1, col_settings2, col_settings3 = st.columns([2, 1, 1])
    
    with col_settings1:
        image_dir = st.text_input("Image Directory", "dataset/images")
        mask_dir = st.text_input("Mask Output Directory", "dataset/masks")
    
    with col_settings2:
        stroke_width = st.slider("Brush Size", 1, 50, 20)
        
    with col_settings3:
        hsv_sensitivity = st.selectbox("HSV Sensitivity", ["low", "medium", "high"], index=1)
    
    stroke_color = "#FFFFFF"
    bg_color = "#000000"
    
    # Create mask directory
    os.makedirs(mask_dir, exist_ok=True)
    
    # Load images
    if os.path.exists(image_dir):
        image_files = [f for f in os.listdir(image_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]
        
        if image_files:
            st.info(f"ðŸ“ **{len(image_files)} gambar ditemukan**")
            
            # Select image
            selected_image = st.selectbox("Pilih Gambar untuk Anotasi", image_files)
            
            if selected_image:
                # Load image
                image_path = os.path.join(image_dir, selected_image)
                image = Image.open(image_path)
                image_np = np.array(image)
                
                st.info(f"Ukuran: {image.size[0]} x {image.size[1]}")
                
                # Auto-detect button
                col_auto1, col_auto2, col_auto3 = st.columns([2, 1, 1])
                
                with col_auto1:
                    st.markdown("### ðŸ¤– Auto-Detection")
                    
                with col_auto2:
                    if st.button("ðŸ” Deteksi HSV", help="Deteksi otomatis area air/banjir"):
                        with st.spinner("Mendeteksi area banjir..."):
                            # Detect water using HSV
                            auto_mask = detect_water_hsv(image_np, sensitivity=hsv_sensitivity)
                            st.session_state['auto_mask'] = auto_mask
                            st.success("âœ… Deteksi selesai! Refine di canvas jika perlu.")
                
                with col_auto3:
                    if st.button("ðŸ”„ Reset Mask"):
                        if 'auto_mask' in st.session_state:
                            del st.session_state['auto_mask']
                        st.rerun()
                
                # Prepare background image for canvas
                if 'auto_mask' in st.session_state:
                    # Create overlay for visualization
                    auto_mask = st.session_state['auto_mask']
                    overlay_img = image_np.copy()
                    overlay_img[auto_mask > 0] = [255, 100, 100]  # Red tint for detected areas
                    background_image = Image.fromarray(overlay_img)
                else:
                    background_image = image
                
                # Main content
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ðŸ–¼ï¸ Gambar Asli")
                    st.image(image, use_column_width=True)
                
                with col2:
                    st.subheader("âœï¸ Edit Mask")
                    st.markdown("**ðŸ¤– Auto-detect HSV atau gambar manual dengan brush**")
                    
                    # Canvas
                    canvas_result = st_canvas(
                        fill_color="rgba(255, 255, 255, 0.3)",
                        stroke_width=stroke_width,
                        stroke_color=stroke_color,
                        background_color=bg_color,
                        background_image=background_image,
                        update_streamlit=True,
                        height=image.size[1],
                        width=image.size[0],
                        drawing_mode="freedraw",
                        key="canvas",
                    )
                
                # Save mask
                st.markdown("---")
                
                col_save1, col_save2, col_save3 = st.columns([2, 1, 1])
                
                with col_save1:
                    mask_filename = st.text_input(
                        "Nama file mask",
                        value=os.path.splitext(selected_image)[0] + "_mask.png"
                    )
                
                with col_save2:
                    if st.button("ðŸ’¾ Simpan Mask", type="primary"):
                        final_mask = None
                        
                        # Prioritas: canvas drawing > auto detection
                        if canvas_result.image_data is not None:
                            # Convert canvas to mask
                            mask = canvas_result.image_data[:, :, :3].astype(np.uint8)
                            mask_gray = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
                            _, canvas_mask = cv2.threshold(mask_gray, 127, 255, cv2.THRESH_BINARY)
                            
                            # Combine with auto mask if exists
                            if 'auto_mask' in st.session_state:
                                auto_mask = st.session_state['auto_mask']
                                # Combine: auto + manual refinement
                                final_mask = cv2.bitwise_or(auto_mask, canvas_mask)
                            else:
                                final_mask = canvas_mask
                        
                        elif 'auto_mask' in st.session_state:
                            # Only auto detection
                            final_mask = st.session_state['auto_mask']
                        
                        if final_mask is not None:
                            # Save
                            mask_path = os.path.join(mask_dir, mask_filename)
                            cv2.imwrite(mask_path, final_mask)
                            st.success(f"âœ… Mask disimpan: {mask_path}")
                            
                            # Clear auto mask after saving
                            if 'auto_mask' in st.session_state:
                                del st.session_state['auto_mask']
                        else:
                            st.warning("âš ï¸ Belum ada mask! Gunakan deteksi HSV atau gambar manual.")
                
                with col_save3:
                    if st.button("ðŸ”„ Reset Canvas"):
                        st.rerun()
                
                # Preview saved masks
                st.markdown("---")
                st.subheader("ðŸ“‚ Mask yang Sudah Disimpan")
                
                saved_masks = [f for f in os.listdir(mask_dir) if f.endswith('.png')]
                
                if saved_masks:
                    st.info(f"Total mask tersimpan: {len(saved_masks)}")
                    
                    # Display saved masks
                    mask_cols = st.columns(4)
                    for idx, mask_file in enumerate(saved_masks[:8]):
                        with mask_cols[idx % 4]:
                            mask_path = os.path.join(mask_dir, mask_file)
                            mask_img = Image.open(mask_path)
                            st.image(mask_img, caption=mask_file, use_column_width=True)
                else:
                    st.info("Belum ada mask yang disimpan")
        else:
            st.warning(f"âš ï¸ Tidak ada gambar di direktori: {image_dir}")
    else:
        st.error(f"âŒ Direktori tidak ditemukan: {image_dir}")


@st.cache_resource
def load_huggingface_model():
    """Load SegFormer model from HuggingFace"""
    try:
        processor = SegformerImageProcessor.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")
        model = SegformerForSemanticSegmentation.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")
        return processor, model
    except Exception as e:
        st.error(f"Error loading HuggingFace model: {e}")
        return None, None


def predict_with_huggingface(image, processor, model):
    """Prediksi menggunakan SegFormer dari HuggingFace"""
    # Preprocess
    inputs = processor(images=image, return_tensors="pt")
    
    # Inference
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
    
    # Resize to original size
    logits = torch.nn.functional.interpolate(
        logits,
        size=image.size[::-1],
        mode="bilinear",
        align_corners=False
    )
    
    # Get segmentation map
    seg_map = logits.argmax(dim=1)[0].cpu().numpy()
    
    # SegFormer ADE20K: class 21 = water, class 60 = river
    # Create binary mask for water-related classes
    water_classes = [21, 60, 26]  # water, river, sea
    water_mask = np.isin(seg_map, water_classes).astype(np.uint8)
    
    return water_mask


def prediction_page():
    """Halaman Prediksi/Inference"""
    st.title("ðŸ” Flood Detection & Segmentation")
    st.markdown("**Upload gambar untuk deteksi dan segmentasi area banjir**")
    
    # Model selection
    st.sidebar.header("ðŸ¤– Pilih Model")
    model_type = st.sidebar.radio(
        "Model Type:",
        ["Custom U-Net (Trained)", "HuggingFace SegFormer (Pre-trained)"],
        help="Pilih model untuk inference"
    )
    
    # Sidebar settings
    st.sidebar.markdown("---")
    st.sidebar.header("âš™ï¸ Pengaturan")
    
    if model_type == "Custom U-Net (Trained)":
        # Custom model settings
        model_path = st.sidebar.text_input(
            "Path Model",
            value="checkpoints/best_model.pth"
        )
        
        # Device selection
        device_option = st.sidebar.selectbox(
            "Device",
            ["CPU", "CUDA (GPU)"]
        )
        device = 'cuda' if device_option == "CUDA (GPU)" and torch.cuda.is_available() else 'cpu'
        
        # Image size
        image_size = st.sidebar.slider("Ukuran Input Model", 256, 1024, 512, 32)
        
        # Threshold
        threshold = st.sidebar.slider("Threshold Deteksi", 0.0, 1.0, 0.5, 0.05)
        
        st.sidebar.markdown("---")
        st.sidebar.info(f"Device aktif: **{device.upper()}**")
        
        # Load model
        if os.path.exists(model_path):
            with st.spinner("Loading custom model..."):
                model, val_iou = load_model(model_path, device)
            
            if model is not None:
                st.sidebar.success("âœ… Custom Model loaded!")
                if val_iou != 'N/A':
                    st.sidebar.metric("Validation IoU", f"{val_iou:.4f}")
            else:
                st.error("Gagal memuat model!")
                return
        else:
            st.warning(f"âš ï¸ Model tidak ditemukan di: `{model_path}`")
            st.info("Silakan latih model terlebih dahulu menggunakan `train.py`")
            return
    
    else:  # HuggingFace SegFormer
        st.sidebar.info("ðŸ“¦ **Model**: nvidia/segformer-b0-finetuned-ade-512-512")
        st.sidebar.markdown("Pre-trained on ADE20K dataset")
        
        # Load HuggingFace model
        with st.spinner("Loading HuggingFace model..."):
            processor, hf_model = load_huggingface_model()
        
        if processor is None or hf_model is None:
            st.error("Gagal memuat HuggingFace model!")
            return
        
        st.sidebar.success("âœ… HuggingFace Model loaded!")
        device = 'cpu'
        threshold = st.sidebar.slider("Threshold Deteksi", 0.0, 1.0, 0.5, 0.05)
    
    # Overlay alpha (common for both)
    alpha = st.sidebar.slider("Transparansi Overlay", 0.0, 1.0, 0.4, 0.05)
    
    # Upload and analyze
    # File uploader
    uploaded_file = st.file_uploader(
        "Pilih gambar banjir untuk dianalisis",
        type=['jpg', 'jpeg', 'png', 'webp'],
        help="Upload gambar dalam format JPG, PNG, atau WEBP"
    )
    
    if uploaded_file is not None:
        # Load image
        image = Image.open(uploaded_file).convert('RGB')
        
        # Create columns
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ðŸ–¼ï¸ Gambar Asli")
            st.image(image, use_column_width=True)
        
        # Predict button
        if st.button("ðŸ” Analisis Banjir", type="primary"):
            with st.spinner("Menganalisis gambar..."):
                # Predict based on model type
                if model_type == "Custom U-Net (Trained)":
                    pred_mask = predict_flood(image, model, device, image_size)
                    binary_mask = (pred_mask > threshold).astype(np.uint8)
                else:  # HuggingFace
                    binary_mask = predict_with_huggingface(image, processor, hf_model)
                
                # Calculate metrics
                total_pixels = binary_mask.size
                flood_pixels = np.sum(binary_mask)
                flood_percentage = (flood_pixels / total_pixels) * 100
                
                # Create overlay
                image_np = np.array(image)
                overlay = overlay_mask(image_np, binary_mask, alpha=alpha, color=[255, 0, 0])
            
            with col2:
                st.subheader("ðŸŽ¯ Hasil Segmentasi")
                st.image(overlay, use_column_width=True)
            
            # Metrics
            st.markdown("---")
            st.subheader("ðŸ“ˆ Statistik Analisis")
            
            metric_col1, metric_col2, metric_col3 = st.columns(3)
            
            with metric_col1:
                st.metric(
                    "Area Banjir",
                    f"{flood_percentage:.2f}%",
                    help="Persentase area yang terdeteksi banjir"
                )
            
            with metric_col2:
                st.metric(
                    "Pixel Banjir",
                    f"{flood_pixels:,}",
                    help="Jumlah pixel yang teridentifikasi sebagai banjir"
                )
            
            with metric_col3:
                severity = "Rendah" if flood_percentage < 20 else "Sedang" if flood_percentage < 50 else "Tinggi"
                st.metric(
                    "Tingkat Keparahan",
                    severity,
                    help="Estimasi tingkat keparahan banjir"
                )
            
            # Download results
            st.markdown("---")
            st.subheader("ðŸ’¾ Download Hasil")
            
            download_col1, download_col2 = st.columns(2)
            
            with download_col1:
                # Save mask
                mask_pil = Image.fromarray((binary_mask * 255).astype(np.uint8))
                mask_buffer = io.BytesIO()
                mask_pil.save(mask_buffer, format='PNG')
                mask_buffer.seek(0)
                
                st.download_button(
                    label="ðŸ“¥ Download Mask",
                    data=mask_buffer,
                    file_name="flood_mask.png",
                    mime="image/png"
                )
            
            with download_col2:
                # Save overlay
                overlay_pil = Image.fromarray(overlay)
                overlay_buffer = io.BytesIO()
                overlay_pil.save(overlay_buffer, format='PNG')
                overlay_buffer.seek(0)
                
                st.download_button(
                    label="ðŸ“¥ Download Overlay",
                    data=overlay_buffer,
                    file_name="flood_overlay.png",
                    mime="image/png"
                )


def about_page():
    """Halaman About"""
    st.title("ðŸ“Š Tentang Sistem")
    
    st.markdown("""
        ### ðŸŽ¯ Tujuan
        Sistem ini dikembangkan untuk mendeteksi dan mensegmentasi area banjir secara otomatis 
        menggunakan teknologi Deep Learning, khususnya arsitektur U-Net.
        
        ### ðŸ”¬ Teknologi
        - **Model**: U-Net dengan encoder-decoder architecture
        - **Framework**: PyTorch
        - **Augmentasi**: Albumentations
        - **Interface**: Streamlit
        
        ### ðŸ“Š Metrik Evaluasi
        - **IoU (Intersection over Union)**: Mengukur overlap antara prediksi dan ground truth
        - **Dice Coefficient**: Metrik similarity untuk segmentasi
        - **Precision & Recall**: Akurasi deteksi area banjir
        
        ### ðŸŽ¨ Interpretasi Warna
        - ðŸ”´ **Merah**: Area yang terdeteksi sebagai banjir
        - âšª **Putih**: Area tanpa banjir
        
    ### âš¡ Performa
    Sistem ini dapat memproses gambar dalam hitungan detik dan memberikan visualisasi 
    yang jelas tentang area yang terdampak banjir.
    """)


def guide_page():
    """Halaman Guide"""
    st.title("ðŸ“– Panduan Penggunaan")
    
    st.markdown("""
        ### 1ï¸âƒ£ Persiapan Model
        ```bash
        # Install dependencies
        pip install -r requirements.txt
        
        # Train model (jika belum ada)
        python train.py --image_dir dataset/images --mask_dir dataset/masks
        ```
        
        ### 2ï¸âƒ£ Menjalankan Aplikasi
        ```bash
        streamlit run app.py
        ```
        
        ### 3ï¸âƒ£ Menggunakan Sistem
        1. Upload gambar banjir melalui tab "Upload Gambar"
        2. Klik tombol "Analisis Banjir"
        3. Lihat hasil segmentasi dan statistik
        4. Download hasil jika diperlukan
        
        ### 4ï¸âƒ£ Pengaturan Advanced
        - **Threshold**: Sesuaikan sensitivitas deteksi (0.3-0.7 recommended)
        - **Transparansi**: Atur transparansi overlay untuk visualisasi yang lebih baik
        - **Image Size**: Ukuran input model (lebih besar = lebih akurat tapi lebih lambat)
        
    ### 5ï¸âƒ£ Tips
    - Gunakan gambar dengan resolusi yang baik untuk hasil optimal
    - Threshold 0.5 biasanya memberikan hasil yang seimbang
    - Gunakan GPU jika tersedia untuk inferensi yang lebih cepat
    """)
    
    st.info("ðŸ’¡ **Tips**: Untuk hasil terbaik, gunakan gambar dengan pencahayaan yang baik dan area banjir yang jelas terlihat.")


def main():
    # Header
    st.title("ðŸŒŠ Flood Segmentation System")
    st.markdown("**Sistem deteksi dan segmentasi area banjir menggunakan Deep Learning**")
    
    # Sidebar Menu
    st.sidebar.title("ðŸ“‹ Menu Navigasi")
    menu = st.sidebar.radio(
        "Pilih Halaman:",
        ["ðŸ  Home", "âœï¸ Annotation Tool", "ðŸ” Detection & Prediction", "ðŸ“Š About", "ðŸ“– Guide"],
        index=0
    )
    
    st.sidebar.markdown("---")
    
    # Routing
    if menu == "ðŸ  Home":
        st.markdown("""
        ## Selamat Datang di Flood Segmentation System! ðŸ‘‹
        
        ### ðŸŽ¯ Fitur Utama:
        
        #### âœï¸ **Annotation Tool**
        Buat mask/label untuk dataset Anda dengan mudah:
        - Upload gambar dari folder
        - Gambar area banjir menggunakan brush
        - Simpan mask untuk training
        
        #### ðŸ” **Detection & Prediction**
        Deteksi area banjir secara otomatis:
        - Upload gambar untuk dianalisis
        - Visualisasi hasil segmentasi
        - Download mask dan overlay
        - Statistik persentase area banjir
        
        #### ðŸ“Š **About**
        Informasi tentang teknologi dan metrik yang digunakan
        
        #### ðŸ“– **Guide**
        Panduan lengkap penggunaan sistem
        
        ---
        
        ### ðŸš€ Quick Start:
        
        1. **Buat Anotasi** â†’ Gunakan menu "Annotation Tool" untuk membuat mask
        2. **Training Model** â†’ Jalankan `python train.py` di terminal
        3. **Prediksi** â†’ Gunakan menu "Detection & Prediction" untuk analisis
        
        ### ðŸ“ Status Dataset:
        """)
        
        # Check dataset status
        image_dir = "dataset/images"
        mask_dir = "dataset/masks"
        
        if os.path.exists(image_dir):
            images = [f for f in os.listdir(image_dir) 
                     if f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]
            st.success(f"âœ… {len(images)} gambar ditemukan di `{image_dir}`")
        else:
            st.error(f"âŒ Folder `{image_dir}` tidak ditemukan")
        
        if os.path.exists(mask_dir):
            masks = [f for f in os.listdir(mask_dir) if f.endswith('.png')]
            if masks:
                st.success(f"âœ… {len(masks)} mask ditemukan di `{mask_dir}`")
            else:
                st.warning(f"âš ï¸ Belum ada mask di `{mask_dir}`. Gunakan Annotation Tool untuk membuat mask.")
        else:
            st.warning(f"âš ï¸ Folder `{mask_dir}` belum ada")
        
        # Check model
        model_path = "checkpoints/best_model.pth"
        if os.path.exists(model_path):
            st.success(f"âœ… Model ditemukan: `{model_path}`")
        else:
            st.warning(f"âš ï¸ Model belum ada. Jalankan training terlebih dahulu: `python train.py`")
        
    elif menu == "âœï¸ Annotation Tool":
        annotation_tool_page()
    
    elif menu == "ðŸ” Detection & Prediction":
        prediction_page()
    
    elif menu == "ðŸ“Š About":
        about_page()
    
    elif menu == "ðŸ“– Guide":
        guide_page()


if __name__ == '__main__':
    main()
